import streamlit as st
from openai import OpenAI

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title("ğŸ“š æ–‡æ›¸å¯¾å¿œãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write(
    "æ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã§ãã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚"
#     "OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚[ã“ã¡ã‚‰](https://platform.openai.com/account/api-keys)ã‹ã‚‰å–å¾—ã§ãã¾ã™ã€‚"
)
st.write("ã€å·¥å¤«ã—ãŸç‚¹ã€‘")
st.write(" ãƒ»APIã‚­ãƒ¼ã‚’ç§˜åŒ¿åŒ–ã—ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«åŸ‹ã‚è¾¼ã¿")
st.write(" ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã¯ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãŒç„¡åŠ¹åŒ–")
st.write(" ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ™‚ã«æ–‡å­—æ•°ã‚’è¡¨ç¤º")
st.write(" ãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã§å›ç­”ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º")
st.write(" ãƒ»ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ä¸€é€£ã®å¯¾è©±ã‚’ã—ãªãŒã‚‰è³ªå•ãŒã§ãã‚‹")

# OpenAI APIã‚­ãƒ¼ã®å…¥åŠ›
openai_api_key = st.secrets.get("OPENAI_API_KEY")
# openai_api_key = st.text_input("OpenAI API Key", type="password")
# if not openai_api_key:
#     st.info("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
# else:
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆ
client = OpenAI(api_key=openai_api_key)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "document_content" not in st.session_state:
    st.session_state.document_content = ""
if "quiz_generated" not in st.session_state:
    st.session_state.quiz_generated = False

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(
    "æ–‡æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (.txt ã¾ãŸã¯ .md)", type=("txt", "md")
)

# ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå ´åˆã€å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
if uploaded_file:
    document = uploaded_file.read().decode()
    # æ–°ã—ã„æ–‡æ›¸ã®å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
    if st.session_state.document_content != document:
        st.session_state.document_content = document
        st.session_state.messages = []  # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢
        st.session_state.quiz_generated = False  # ã‚¯ã‚¤ã‚ºç”Ÿæˆãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ï¼ˆ{len(document):,} æ–‡å­—ï¼‰")

# æ–‡æ›¸ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
if uploaded_file and st.session_state.document_content:
    
    # ã‚¯ã‚¤ã‚ºç”Ÿæˆãƒœã‚¿ãƒ³
    col1, col2 = st.columns([1, 5])
    with col1:
        if st.button("ğŸ“ ã‚¯ã‚¤ã‚ºå‡ºé¡Œ", disabled=st.session_state.quiz_generated):
            # ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆ
            with st.chat_message("assistant"):
                st.markdown("ğŸ“ æ–‡æ›¸ã®å†…å®¹ã«é–¢ã™ã‚‹ã‚¯ã‚¤ã‚ºã‚’å‡ºé¡Œã—ã¾ã™...")
                
                # ã‚¯ã‚¤ã‚ºç”Ÿæˆç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                quiz_messages = [
                    {
                        "role": "system",
                        "content": f"ã‚ãªãŸã¯æ•™è‚²è€…ã§ã™ã€‚ä»¥ä¸‹ã®æ–‡æ›¸ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ã‚¯ã‚¤ã‚ºã‚’1å•å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚\n\næ–‡æ›¸å†…å®¹:\n{st.session_state.document_content}"
                    },
                    {
                        "role": "user",
                        "content": "ã“ã®æ–‡æ›¸ã®å†…å®¹ã«ã¤ã„ã¦ã€ç†è§£åº¦ã‚’ç¢ºèªã™ã‚‹ã‚¯ã‚¤ã‚ºã‚’1å•å‡ºé¡Œã—ã¦ãã ã•ã„ã€‚é¸æŠè‚¢å½¢å¼ã¾ãŸã¯è¨˜è¿°å¼ã§ã€é©åˆ‡ãªé›£æ˜“åº¦ã®å•é¡Œã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
                    }
                ]
                
                # ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆ
                stream = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=quiz_messages,
                    stream=True,
                )
                
                quiz_response = st.write_stream(stream)
                
            # ã‚¯ã‚¤ã‚ºã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": quiz_response})
            st.session_state.quiz_generated = True
            st.rerun()
    
    with col2:
        if st.button("ğŸ”„ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state.messages = []
            st.session_state.quiz_generated = False
            st.rerun()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("æ–‡æ›¸ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ã€ã¾ãŸã¯ã‚¯ã‚¤ã‚ºã«å›ç­”ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ãƒ»è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            # APIç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            # æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯æ–‡æ›¸å†…å®¹ã‚’å«ã‚ã‚‹
            if len(st.session_state.messages) == 1:
                # åˆå›ã®è³ªå•
                messages = [
                    {
                        "role": "user",
                        "content": f"ä»¥ä¸‹ã¯æ–‡æ›¸ã®å†…å®¹ã§ã™: {st.session_state.document_content} \n\n---\n\n {prompt}",
                    }
                ]
            else:
                # 2å›ç›®ä»¥é™ã¯ã€æ–‡æ›¸å†…å®¹ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¨­å®šã—ã€ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
                messages = [
                    {
                        "role": "system",
                        "content": f"ã‚ãªãŸã¯ä»¥ä¸‹ã®æ–‡æ›¸ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦ã€æ–‡è„ˆã«æ²¿ã£ãŸå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚¯ã‚¤ã‚ºã®å›ç­”ã«å¯¾ã—ã¦ã¯ã€æ­£èª¤ã‚’åˆ¤å®šã—ã€è§£èª¬ã‚’åŠ ãˆã¦ãã ã•ã„ã€‚\n\næ–‡æ›¸å†…å®¹:\n{st.session_state.document_content}",
                    }
                ]
                # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
                for msg in st.session_state.messages[:-1]:  # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆä»Šè¿½åŠ ã—ãŸã‚‚ã®ï¼‰ä»¥å¤–
                    messages.append({"role": msg["role"], "content": msg["content"]})
                # ç¾åœ¨ã®è³ªå•ã‚’è¿½åŠ 
                messages.append({"role": "user", "content": prompt})

            # OpenAI APIã§å¿œç­”ã‚’ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
            stream = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                stream=True,
            )

            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å¿œç­”ã‚’è¡¨ç¤º
            response = st.write_stream(stream)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ä¿å­˜
        st.session_state.messages.append({"role": "assistant", "content": response})